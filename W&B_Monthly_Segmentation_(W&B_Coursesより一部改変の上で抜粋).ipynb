{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myzk-a/Matlab/blob/main/W%26B_Monthly_Segmentation_(W%26B_Courses%E3%82%88%E3%82%8A%E4%B8%80%E9%83%A8%E6%94%B9%E5%A4%89%E3%81%AE%E4%B8%8A%E3%81%A7%E6%8A%9C%E7%B2%8B).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46RflqEh63sg"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/nejumi/images/master/images/header.png\" alt=\"header\">"
      ],
      "id": "46RflqEh63sg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DNydZRMTLmP"
      },
      "source": [
        "# W&Bによるセマンティックセグメンテーションタスクの実験管理とイメージオーバーレイとテーブルによる可視化"
      ],
      "id": "-DNydZRMTLmP"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76b1a803",
        "outputId": "b88c205e-9f0f-441b-927c-79baa73f64be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-08 01:54:40--  https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "\rrequirements.txt      0%[                    ]       0  --.-KB/s               \rrequirements.txt    100%[===================>]      82  --.-KB/s    in 0s      \n",
            "\n",
            "2025-04-08 01:54:40 (4.43 MB/s) - ‘requirements.txt’ saved [82/82]\n",
            "\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# 依存関係のインストール（一度だけ実行）\n",
        "!wget https://raw.githubusercontent.com/wandb/edu/main/mlops-001/lesson1/requirements.txt\n",
        "!pip install -r requirements.txt -qqq"
      ],
      "id": "76b1a803"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4723ae62-c55d-4c8f-9157-43c29189a2ff"
      },
      "source": [
        "# ベースラインモデルの構築\n",
        "\n",
        "<!--- @wandbcode{course-lesson1} -->\n",
        "\n",
        "このnotebookでは、上記のセマンティックセグメンテーションタスクに対するベースラインを構築していきましょう。試行錯誤を素早く繰り返すのにnotebookは手軽な方法です。後ほどスクリプトにリファクタしてsweepsによるハイパーパラメータ最適化もできるようにします。"
      ],
      "id": "4723ae62-c55d-4c8f-9157-43c29189a2ff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29116dec"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "import pandas as pd\n",
        "from fastai.vision.all import *\n",
        "from fastai.callback.wandb import WandbCallback\n",
        "from types import SimpleNamespace"
      ],
      "id": "29116dec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iWI9NZnbJUF",
        "outputId": "10f64344-653f-4ea6-919a-61179704d4b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ],
      "id": "-iWI9NZnbJUF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c79d360d"
      },
      "outputs": [],
      "source": [
        "params = SimpleNamespace(\n",
        "    WANDB_PROJECT = \"mlops-course-001\",\n",
        "    ENTITY = \"japan-demo\", # your entity (user name or team name) here.\n",
        "    BDD_CLASSES = {i:c for i,c in enumerate(['background', 'road', 'traffic light', 'traffic sign', 'person', 'vehicle', 'bicycle'])},\n",
        "    RAW_DATA_AT = 'bdd_simple_1k',\n",
        "    PROCESSED_DATA_AT = 'bdd_simple_1k_split',\n",
        ")"
      ],
      "id": "c79d360d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCtHHz2-peGf"
      },
      "source": [
        "# wandb.Tableを具体的にここで作成しています"
      ],
      "id": "jCtHHz2-peGf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d6f58e8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "CLASS_INDEX = {v:k for k,v in params.BDD_CLASSES.items()}\n",
        "\n",
        "def iou_per_class(inp, targ):\n",
        "    \"Compute iou per class\"\n",
        "    iou_scores = []\n",
        "    for c in range(inp.shape[0]):\n",
        "        dec_preds = inp.argmax(dim=0)\n",
        "        p = torch.where(dec_preds == c, 1, 0)\n",
        "        t = torch.where(targ == c, 1, 0)\n",
        "        c_inter = (p * t).float().sum().item()\n",
        "        c_union = (p + t).float().sum().item()\n",
        "        iou_scores.append(c_inter / (c_union - c_inter) if c_union > 0 else np.nan)\n",
        "    return iou_scores\n",
        "\n",
        "def create_row(sample, pred_label, prediction, class_labels):\n",
        "    \"\"\"\"A simple function to create a row of (img, target, prediction, and scores...)\"\"\"\n",
        "    (image, label) = sample\n",
        "    # メトリクスを計算\n",
        "    iou_scores = iou_per_class(prediction, label)\n",
        "    image = image.permute(1, 2, 0)\n",
        "    row =[wandb.Image(\n",
        "                image,\n",
        "                masks={\n",
        "                    \"predictions\": {\n",
        "                        \"mask_data\": pred_label[0].numpy(),\n",
        "                        \"class_labels\": class_labels,\n",
        "                    },\n",
        "                    \"ground_truths\": {\n",
        "                        \"mask_data\": label.numpy(),\n",
        "                        \"class_labels\": class_labels,\n",
        "                    },\n",
        "                },\n",
        "            ),\n",
        "            *iou_scores,\n",
        "    ]\n",
        "    return row\n",
        "\n",
        "def create_iou_table(samples, outputs, predictions, class_labels):\n",
        "    \"Creates a wandb table with predictions and targets side by side\"\n",
        "\n",
        "    def _to_str(l):\n",
        "        return [f'{str(x)} IoU' for x in l]\n",
        "\n",
        "    items = list(zip(samples, outputs, predictions))\n",
        "\n",
        "    table = wandb.Table(\n",
        "        columns=[\"Image\"]\n",
        "        + _to_str(class_labels.values()),\n",
        "    )\n",
        "    # we create one row per sample\n",
        "    for item in progress_bar(items):\n",
        "        table.add_data(*create_row(*item, class_labels=class_labels))\n",
        "\n",
        "    return table\n",
        "\n",
        "def get_predictions(learner, test_dl=None, max_n=None):\n",
        "    \"\"\"Return the samples = (x,y) and outputs (model predictions decoded), and predictions (raw preds)\"\"\"\n",
        "    test_dl = learner.dls.valid if test_dl is None else test_dl\n",
        "    inputs, predictions, targets, outputs = learner.get_preds(\n",
        "        dl=test_dl, with_input=True, with_decoded=True\n",
        "    )\n",
        "    x, y, samples, outputs = learner.dls.valid.show_results(\n",
        "        tuplify(inputs) + tuplify(targets), outputs, show=False, max_n=max_n\n",
        "    )\n",
        "    return samples, outputs, predictions\n",
        "\n",
        "    def value(self): return self.inter/(self.union-self.inter) if self.union > 0 else None\n",
        "\n",
        "class MIOU(DiceMulti):\n",
        "    @property\n",
        "    def value(self):\n",
        "        binary_iou_scores = np.array([])\n",
        "        for c in self.inter:\n",
        "            binary_iou_scores = np.append(binary_iou_scores, \\\n",
        "                                          self.inter[c]/(self.union[c]-self.inter[c]) if self.union[c] > 0 else np.nan)\n",
        "        return np.nanmean(binary_iou_scores)\n",
        "\n",
        "class IOU(DiceMulti):\n",
        "    @property\n",
        "    def value(self):\n",
        "        c=CLASS_INDEX[self.nm]\n",
        "        return self.inter[c]/(self.union[c]-self.inter[c]) if self.union[c] > 0 else np.nan\n",
        "\n",
        "class BackgroundIOU(IOU): nm = 'background'\n",
        "class RoadIOU(IOU): nm = 'road'\n",
        "class TrafficLightIOU(IOU): nm = 'traffic light'\n",
        "class TrafficSignIOU(IOU): nm = 'traffic sign'\n",
        "class PersonIOU(IOU): nm = 'person'\n",
        "class VehicleIOU(IOU): nm = 'vehicle'\n",
        "class BicycleIOU(IOU): nm = 'bicycle'\n",
        "\n",
        "\n",
        "class IOUMacro(DiceMulti):\n",
        "    @property\n",
        "    def value(self):\n",
        "        c=CLASS_INDEX[self.nm]\n",
        "        if c not in self.count: return np.nan\n",
        "        else: return self.macro[c]/self.count[c] if self.count[c] > 0 else np.nan\n",
        "\n",
        "    def reset(self): self.macro,self.count = {},{}\n",
        "\n",
        "    def accumulate(self, learn):\n",
        "        pred,targ = learn.pred.argmax(dim=self.axis), learn.y\n",
        "        for c in range(learn.pred.shape[self.axis]):\n",
        "            p = torch.where(pred == c, 1, 0)\n",
        "            t = torch.where(targ == c, 1, 0)\n",
        "            c_inter = (p*t).float().sum(dim=(1,2))\n",
        "            c_union = (p+t).float().sum(dim=(1,2))\n",
        "            m = c_inter / (c_union - c_inter)\n",
        "            macro = m[~torch.any(m.isnan())]\n",
        "            count = macro.shape[1]\n",
        "\n",
        "            if count > 0:\n",
        "                msum = macro.sum().item()\n",
        "                if c in self.count:\n",
        "                    self.count[c] += count\n",
        "                    self.macro[c] += msum\n",
        "                else:\n",
        "                    self.count[c] = count\n",
        "                    self.macro[c] = msum\n",
        "\n",
        "\n",
        "class MIouMacro(IOUMacro):\n",
        "    @property\n",
        "    def value(self):\n",
        "        binary_iou_scores = np.array([])\n",
        "        for c in self.count:\n",
        "            binary_iou_scores = np.append(binary_iou_scores, self.macro[c]/self.count[c] if self.count[c] > 0 else np.nan)\n",
        "        return np.nanmean(binary_iou_scores)\n",
        "\n",
        "\n",
        "class BackgroundIouMacro(IOUMacro): nm = 'background'\n",
        "class RoadIouMacro(IOUMacro): nm = 'road'\n",
        "class TrafficLightIouMacro(IOUMacro): nm = 'traffic light'\n",
        "class TrafficSignIouMacro(IOUMacro): nm = 'traffic sign'\n",
        "class PersonIouMacro(IOUMacro): nm = 'person'\n",
        "class VehicleIouMacro(IOUMacro): nm = 'vehicle'\n",
        "class BicycleIouMacro(IOUMacro): nm = 'bicycle'\n",
        "\n",
        "\n",
        "def display_diagnostics(learner, dls=None, return_vals=False):\n",
        "    \"\"\"\n",
        "    Display a confusion matrix for the unet learner.\n",
        "    If `dls` is None it will get the validation set from the Learner\n",
        "\n",
        "    You can create a test dataloader using the `test_dl()` method like so:\n",
        "    >> dls = ... # You usually create this from the DataBlocks api, in this library it is get_data()\n",
        "    >> tdls = dls.test_dl(test_dataframe, with_labels=True)\n",
        "\n",
        "    See: https://docs.fast.ai/tutorial.pets.html#adding-a-test-dataloader-for-inference\n",
        "\n",
        "    \"\"\"\n",
        "    probs, targs = learner.get_preds(dl = dls)\n",
        "    preds = probs.argmax(dim=1)\n",
        "    classes = list(params.BDD_CLASSES.values())\n",
        "    y_true = targs.flatten().numpy()\n",
        "    y_pred = preds.flatten().numpy()\n",
        "\n",
        "    tdf, pdf = [pd.DataFrame(r).value_counts().to_frame(c) for r,c in zip((y_true, y_pred) , ['y_true', 'y_pred'])]\n",
        "    countdf = tdf.join(pdf, how='outer').reset_index(drop=True).fillna(0).astype(int).rename(index= params.BDD_CLASSES)\n",
        "    countdf = countdf/countdf.sum()\n",
        "    display(Markdown('### % Of Pixels In Each Class'))\n",
        "    display(countdf.style.format('{:.1%}'))\n",
        "\n",
        "\n",
        "    disp = ConfusionMatrixDisplay.from_predictions(y_true=y_true, y_pred=y_pred,\n",
        "                                                   display_labels=classes,\n",
        "                                                   normalize='pred')\n",
        "    fig = disp.ax_.get_figure()\n",
        "    fig.set_figwidth(10)\n",
        "    fig.set_figheight(10)\n",
        "    disp.ax_.set_title('Confusion Matrix (by Pixels)', fontdict={'fontsize': 32, 'fontweight': 'medium'})\n",
        "    fig.show()\n",
        "\n",
        "    if return_vals: return countdf, disp"
      ],
      "id": "3d6f58e8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e0871e5-c07d-4a8b-817b-388c2e9bf7d1"
      },
      "source": [
        "Again, we're importing some global configuration parameters from `params.py` file. We have also defined some helper functions in `utils.py` - for example metrics we will track during our experiments.\n",
        "\n",
        "Let's now create a `train_config` that we'll pass to W&B `run` to control training hyperparameters."
      ],
      "id": "6e0871e5-c07d-4a8b-817b-388c2e9bf7d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cff6b8ee"
      },
      "outputs": [],
      "source": [
        "train_config = SimpleNamespace(\n",
        "    framework=\"fastai\",\n",
        "    img_size=(180, 320),\n",
        "    batch_size=8,\n",
        "    augment=True, # use data augmentation\n",
        "    epochs=10,\n",
        "    lr=2e-3,\n",
        "    pretrained=True,  # whether to use pretrained encoder\n",
        "    seed=42,\n",
        ")"
      ],
      "id": "cff6b8ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q00011E8o9y5"
      },
      "source": [
        "# ここからトラッキング開始です"
      ],
      "id": "Q00011E8o9y5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38f014f3-d78f-4f5b-b038-d8020de43930"
      },
      "source": [
        "再現性のためにseedを設定しておきましょう"
      ],
      "id": "38f014f3-d78f-4f5b-b038-d8020de43930"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc6765f6"
      },
      "outputs": [],
      "source": [
        "set_seed(train_config.seed, reproducible=True)"
      ],
      "id": "fc6765f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "32483e4d",
        "outputId": "4529d504-e16f-4802-d314-d39063da148a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231030_052424-8ofn4481</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/japan-demo/mlops-course-001/runs/8ofn4481' target=\"_blank\">costumed-mausoleum-1</a></strong> to <a href='https://wandb.ai/japan-demo/mlops-course-001' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/japan-demo/mlops-course-001' target=\"_blank\">https://wandb.ai/japan-demo/mlops-course-001</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/japan-demo/mlops-course-001/runs/8ofn4481' target=\"_blank\">https://wandb.ai/japan-demo/mlops-course-001/runs/8ofn4481</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(project=params.WANDB_PROJECT, entity=params.ENTITY, job_type=\"training\", config=train_config)"
      ],
      "id": "32483e4d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be7c1872-fc08-4304-9842-203d9ac45371"
      },
      "source": [
        "通常通り、W&B Artifactsを使うことでモデルのlineageをトラックします"
      ],
      "id": "be7c1872-fc08-4304-9842-203d9ac45371"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "df839467",
        "outputId": "0a97f492-06ae-462f-efcf-6a2d3fa2b35d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact bdd_simple_1k_split:v0, 813.25MB. 4010 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   4010 of 4010 files downloaded.  \n",
            "Done. 0:0:44.7\n"
          ]
        }
      ],
      "source": [
        "processed_data_at = run.use_artifact('yuya-yamamoto/mlops-course-001/bdd_simple_1k_split:v0', type='split_data')\n",
        "processed_dataset_dir = Path(processed_data_at.download())\n",
        "df = pd.read_csv(processed_dataset_dir / 'data_split.csv')"
      ],
      "id": "df839467"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77170345-96d3-4371-a4e9-5ea3b15e2cdb"
      },
      "source": [
        "ここではホールドアウトセットは用いません。`is_valid`カラムはtrainerに学習と検定の分割について伝えるために設定しています。"
      ],
      "id": "77170345-96d3-4371-a4e9-5ea3b15e2cdb"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rAumgv0A-X4i"
      },
      "id": "rAumgv0A-X4i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5a34e1d7"
      },
      "outputs": [],
      "source": [
        "df = df[df.Stage != 'test'].reset_index(drop=True)\n",
        "df['is_valid'] = df.Stage == 'valid'"
      ],
      "id": "5a34e1d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "65ae3d60"
      },
      "outputs": [],
      "source": [
        "def label_func(fname):\n",
        "    return (fname.parent.parent/\"labels\")/f\"{fname.stem}_mask.png\""
      ],
      "id": "65ae3d60"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7fb25d8-50b0-4c14-9d52-d14725e024c9"
      },
      "source": [
        "`fastai`の`DataBlock` APIを用いてデータをモデルの学習と検証に供給します。"
      ],
      "id": "e7fb25d8-50b0-4c14-9d52-d14725e024c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1f713864"
      },
      "outputs": [],
      "source": [
        "# assign paths\n",
        "df[\"image_fname\"] = [processed_dataset_dir/f'images/{f}' for f in df.File_Name.values]\n",
        "df[\"label_fname\"] = [label_func(f) for f in df.image_fname.values]"
      ],
      "id": "1f713864"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4268334e"
      },
      "outputs": [],
      "source": [
        "def get_data(df, bs=4, img_size=(180, 320), augment=True):\n",
        "    block = DataBlock(blocks=(ImageBlock, MaskBlock(codes=params.BDD_CLASSES)),\n",
        "                  get_x=ColReader(\"image_fname\"),\n",
        "                  get_y=ColReader(\"label_fname\"),\n",
        "                  splitter=ColSplitter(),\n",
        "                  item_tfms=Resize(img_size),\n",
        "                  batch_tfms=aug_transforms() if augment else None,\n",
        "                 )\n",
        "    return block.dataloaders(df, bs=bs)"
      ],
      "id": "4268334e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "929f7975-ff29-4692-89b3-7f7596aecb0a"
      },
      "source": [
        "We are using `wandb.config` to track our training hyperparameters."
      ],
      "id": "929f7975-ff29-4692-89b3-7f7596aecb0a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f214f2f1"
      },
      "outputs": [],
      "source": [
        "config = wandb.config"
      ],
      "id": "f214f2f1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "58544078",
        "outputId": "3ce7e9ea-433a-4ccc-c454-0516fcd551e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/torch_core.py:263: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
            "  return getattr(torch, 'has_mps', False)\n"
          ]
        }
      ],
      "source": [
        "dls = get_data(df, bs=config.batch_size, img_size=config.img_size, augment=config.augment)"
      ],
      "id": "58544078"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475d4e69-d8ec-4093-a8e4-0f09b0979887"
      },
      "source": [
        "We will use intersection over union metrics: mean across all classes (MIOU) and IOU for each class separately. Our model will be a `unet` based on pretrained `resnet18` backbone."
      ],
      "id": "475d4e69-d8ec-4093-a8e4-0f09b0979887"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a9fd4610",
        "outputId": "892ef7b9-461f-441e-f556-7186c49fa3f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 68.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "metrics = [MIOU(), BackgroundIOU(), RoadIOU(), TrafficLightIOU(), \\\n",
        "           TrafficSignIOU(), PersonIOU(), VehicleIOU(), BicycleIOU()]\n",
        "\n",
        "learn = unet_learner(dls, arch=resnet18, pretrained=config.pretrained, metrics=metrics)"
      ],
      "id": "a9fd4610"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88d45330-cfc2-44e9-8c0c-5eee417050b1"
      },
      "source": [
        "In fastai we already have a callback that integrates tightly with W&B, we only need to pass the WandbCallback to the learner and we are ready to go. The callback will log all the useful variables for us. For example, whatever metric we pass to the learner will be tracked by the callback."
      ],
      "id": "88d45330-cfc2-44e9-8c0c-5eee417050b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMmaCD62pLZR"
      },
      "source": [
        "# fastaiもW&Bインテグレーションが用意されており、簡単に使うことができます"
      ],
      "id": "qMmaCD62pLZR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "87db7e5b"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    SaveModelCallback(monitor='miou'),\n",
        "    WandbCallback(log_preds=False, log_model=True)\n",
        "]"
      ],
      "id": "87db7e5b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dfe3c60-f4af-4e21-874d-13f119d03dd5"
      },
      "source": [
        "Let's train our model!\n",
        "\n"
      ],
      "id": "7dfe3c60-f4af-4e21-874d-13f119d03dd5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "a1846493",
        "outputId": "d2469300-63dd-46f3-ac08-1117d9282e41"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='1' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      10.00% [1/10 51:36&lt;7:44:25]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>miou</th>\n",
              "      <th>background_iou</th>\n",
              "      <th>road_iou</th>\n",
              "      <th>traffic_light_iou</th>\n",
              "      <th>traffic_sign_iou</th>\n",
              "      <th>person_iou</th>\n",
              "      <th>vehicle_iou</th>\n",
              "      <th>bicycle_iou</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.499637</td>\n",
              "      <td>0.321845</td>\n",
              "      <td>0.317601</td>\n",
              "      <td>0.872421</td>\n",
              "      <td>0.752962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.597822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51:35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "      <progress value='16' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      16.00% [16/100 08:02&lt;42:12 0.4566]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with miou value: 0.3176006357112852.\n"
          ]
        }
      ],
      "source": [
        "learn.fit_one_cycle(config.epochs, config.lr, cbs=callbacks)"
      ],
      "id": "a1846493"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "976ac11f-ad6c-4f9d-b2b0-6acb8d7af34a"
      },
      "source": [
        "We will log a table with model predictions and ground truth to W&B, so that we can do error analysis in the W&B dashboard."
      ],
      "id": "976ac11f-ad6c-4f9d-b2b0-6acb8d7af34a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrWUwlV5pYVS"
      },
      "source": [
        "# テーブルをロギングします"
      ],
      "id": "QrWUwlV5pYVS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "387dc2d8"
      },
      "outputs": [],
      "source": [
        "samples, outputs, predictions = get_predictions(learn)\n",
        "table = create_iou_table(samples, outputs, predictions, params.BDD_CLASSES)\n",
        "wandb.log({\"pred_table\":table})"
      ],
      "id": "387dc2d8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b913a7ca-1250-4a61-a011-d333110bb927"
      },
      "source": [
        "We are reloading the model from the best checkpoint at the end and saving it. To make sure we track the final metrics correctly, we will validate the model again and save the final loss and metrics to `wandb.summary`."
      ],
      "id": "b913a7ca-1250-4a61-a011-d333110bb927"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6ec120e"
      },
      "outputs": [],
      "source": [
        "scores = learn.validate()\n",
        "metric_names = ['final_loss'] + [f'final_{x.name}' for x in metrics]\n",
        "final_results = {metric_names[i] : scores[i] for i in range(len(scores))}\n",
        "for k,v in final_results.items():\n",
        "    wandb.summary[k] = v"
      ],
      "id": "d6ec120e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53f86720"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ],
      "id": "53f86720"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff7129c3"
      },
      "outputs": [],
      "source": [
        "# 以下のようにmagic commandを使って、Notebook内でダッシュボードを表示することもできます。\n",
        "# entityとプロジェクト名などはご自身のものに変えて実行してください。\n",
        "#%%wandb yuya-yamamoto/mlops-course-001/ -h 2048"
      ],
      "id": "ff7129c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUNqht9DeH4W"
      },
      "outputs": [],
      "source": [
        "precious_id = run.id\n",
        "\n",
        "run = wandb.init(id=precious_id, resume='allow')\n",
        "\n",
        "model.load(...)\n",
        "y_pred = model.predict(...)\n",
        "3d_iou = evaluate(y_true, y_pred)\n",
        "run.log({\"3d_iou\":3d_iou})\n",
        "\n",
        "run.finish()"
      ],
      "id": "EUNqht9DeH4W"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}